"""
Dự đoán điểm chuẩn đại học 2024
Chiến lược: Tính tỉ lệ thí sinh cạnh tranh theo vùng địa lý (bán kính 500km)

Time-based Split:
- Train/Valid: 2019-2022 → 2023 (80/20)
- Test: 2020-2023 → 2024

Author: Generated by Antigravity
"""

import os
import math
import warnings
from typing import List, Tuple, Dict

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

warnings.filterwarnings('ignore')

# Paths
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, 'data')


# =============================================================================
# 1. HAVERSINE DISTANCE
# =============================================================================

def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    """
    Tính khoảng cách (km) giữa 2 điểm trên trái đất sử dụng công thức Haversine.
    """
    R = 6371  # Bán kính trái đất (km)
    
    lat1_rad = math.radians(lat1)
    lat2_rad = math.radians(lat2)
    delta_lat = math.radians(lat2 - lat1)
    delta_lon = math.radians(lon2 - lon1)
    
    a = math.sin(delta_lat / 2) ** 2 + \
        math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lon / 2) ** 2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    
    return R * c


# =============================================================================
# 2. DATA LOADING
# =============================================================================

def load_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, Dict[str, pd.DataFrame]]:
    """Load tất cả dữ liệu cần thiết."""
    schools = pd.read_csv(os.path.join(DATA_DIR, 'school_with_coords.csv'))
    provinces = pd.read_csv(os.path.join(DATA_DIR, 'province.csv'))
    
    pretrain = pd.read_csv(os.path.join(DATA_DIR, 'data_pretrain_filled.csv'), encoding='utf-8-sig')
    pretrain.columns = [
        'school_code', 'major_code', 'major_name',
        'combo_2019', 'combo_2020', 'combo_2021', 'combo_2022', 'combo_2023', 'combo_2024',
        'score_2019', 'score_2020', 'score_2021', 'score_2022', 'score_2023', 'score_2024'
    ]
    
    summaries = {}
    for year in range(2019, 2025):
        summary_path = os.path.join(DATA_DIR, f'{year}_summary.csv')
        if os.path.exists(summary_path):
            df = pd.read_csv(summary_path, encoding='utf-8-sig')
            df.columns = ['province_code', 'year', 'subject_combo', 'num_students', 'score_threshold']
            df['province_code'] = df['province_code'].astype(str).str.zfill(2)
            summaries[year] = df
    
    return schools, provinces, pretrain, summaries


# =============================================================================
# 3. GEOGRAPHIC FILTERING
# =============================================================================

def get_provinces_within_radius(
    school_code: str,
    schools: pd.DataFrame,
    provinces: pd.DataFrame,
    radius_km: float = 500
) -> List[str]:
    """Lấy danh sách mã tỉnh trong bán kính từ trường."""
    school_row = schools[schools['MA_TRUONG'] == school_code]
    if school_row.empty:
        return provinces['MA_TINH'].astype(str).str.zfill(2).tolist()
    
    school_lat = school_row['VI_DO'].iloc[0]
    school_lon = school_row['KINH_DO'].iloc[0]
    
    nearby_provinces = []
    for _, prov in provinces.iterrows():
        dist = haversine_distance(school_lat, school_lon, prov['VI_DO'], prov['KINH_DO'])
        if dist <= radius_km:
            nearby_provinces.append(str(prov['MA_TINH']).zfill(2))
    
    return nearby_provinces


# =============================================================================
# 4. COMPETITION RATIO CALCULATION
# =============================================================================

def floor_to_step(value: float, step: float = 0.05) -> float:
    """Làm tròn xuống theo bước nhảy (mặc định 0.05)"""
    return math.floor(value / step) * step


def calculate_competition_ratio(
    year: int,
    subject_combos: List[str],
    cutoff_score: float,
    province_codes: List[str],
    summaries: Dict[int, pd.DataFrame],
    base_score: float = 12.5
) -> float:
    """Tính tỉ lệ thí sinh cạnh tranh."""
    if year not in summaries:
        return np.nan
    
    summary = summaries[year]
    
    mask = (
        summary['province_code'].isin(province_codes) &
        summary['subject_combo'].isin(subject_combos)
    )
    filtered = summary[mask]
    
    if filtered.empty:
        return np.nan
    
    cutoff_df = filtered[filtered['score_threshold'] == cutoff_score]
    num_above_cutoff = cutoff_df['num_students'].sum()
    
    base_df = filtered[filtered['score_threshold'] == base_score]
    num_above_base = base_df['num_students'].sum()
    
    if num_above_base == 0:
        return np.nan
    
    return num_above_cutoff / num_above_base


def get_students_above_score(
    year: int,
    subject_combos: List[str],
    score_threshold: float,
    province_codes: List[str],
    summaries: Dict[int, pd.DataFrame]
) -> int:
    """Lấy số thí sinh đạt >= score_threshold trong vùng."""
    if year not in summaries:
        return 0
    
    summary = summaries[year]
    mask = (
        summary['province_code'].isin(province_codes) &
        summary['subject_combo'].isin(subject_combos) &
        (summary['score_threshold'] == score_threshold)
    )
    return summary[mask]['num_students'].sum()


def lookup_score_from_ratio(
    target_year: int,
    subject_combos: List[str],
    target_ratio: float,
    province_codes: List[str],
    summaries: Dict[int, pd.DataFrame],
    base_score: float = 12.5
) -> float:
    """
    Tìm mốc điểm trong năm target mà tỉ lệ cạnh tranh ≈ target_ratio.
    """
    if target_year not in summaries or pd.isna(target_ratio):
        return np.nan
    
    above_base = get_students_above_score(
        target_year, subject_combos, base_score, province_codes, summaries
    )
    if above_base == 0:
        return np.nan
    
    target_students = target_ratio * above_base
    
    summary = summaries[target_year]
    mask = (
        summary['province_code'].isin(province_codes) &
        summary['subject_combo'].isin(subject_combos)
    )
    filtered = summary[mask]
    
    if filtered.empty:
        return np.nan
    
    score_students = filtered.groupby('score_threshold')['num_students'].sum().reset_index()
    score_students = score_students.sort_values('score_threshold')
    
    best_score = base_score
    min_diff = float('inf')
    
    for _, row in score_students.iterrows():
        diff = abs(row['num_students'] - target_students)
        if diff < min_diff:
            min_diff = diff
            best_score = row['score_threshold']
    
    return best_score


# =============================================================================
# 5. FEATURE ENGINEERING
# =============================================================================

def parse_subject_combos(combo_str: str) -> List[str]:
    """Parse chuỗi tổ hợp môn thành list"""
    if pd.isna(combo_str):
        return []
    return [c.strip() for c in str(combo_str).split(';')]


def build_training_features(
    pretrain: pd.DataFrame,
    schools: pd.DataFrame,
    provinces: pd.DataFrame,
    summaries: Dict[int, pd.DataFrame],
    target_year: int,
    radius_km: float = 500
) -> pd.DataFrame:
    """
    Xây dựng dataset với features cho training/prediction.
    
    Args:
        target_year: Năm cần dự đoán (2023 cho train, 2024 cho test)
    
    Features:
        - score_(target-1..4): Điểm chuẩn 4 năm trước
        - ratio_(target-1..4): Tỉ lệ cạnh tranh 4 năm trước
        - weighted_ratio_score: Điểm lookup từ weighted ratio trong năm target
    """
    records = []
    weights = [4, 3, 2, 1]  # Trọng số cho n-1, n-2, n-3, n-4
    
    for _, row in pretrain.iterrows():
        school_code = row['school_code']
        major_code = row['major_code']
        major_name = row['major_name']
        
        # Lấy danh sách tỉnh trong bán kính
        nearby_provinces = get_provinces_within_radius(
            school_code, schools, provinces, radius_km
        )
        
        # Lấy điểm chuẩn và combos các năm (4 năm trước target)
        try:
            scores = []
            ratios = []
            combos_list = []
            
            for offset in [1, 2, 3, 4]:
                year = target_year - offset
                score = row.get(f'score_{year}', np.nan)
                combo = parse_subject_combos(row.get(f'combo_{year}', ''))
                scores.append(score)
                combos_list.append(combo)
                
                # Tính ratio cho năm này
                if not pd.isna(score) and combo:
                    cutoff = floor_to_step(score)
                    ratio = calculate_competition_ratio(
                        year, combo, cutoff, nearby_provinces, summaries
                    )
                else:
                    ratio = np.nan
                ratios.append(ratio)
            
            score_prev, score_2y, score_3y, score_4y = scores
            ratio_prev, ratio_2y, ratio_3y, ratio_4y = ratios
            score_target = row[f'score_{target_year}']
            
        except KeyError:
            continue
        
        if pd.isna(score_prev):
            continue
        
        # Tính weighted ratio
        valid_ratios = []
        valid_weights = []
        for r, w in zip(ratios, weights):
            if not pd.isna(r):
                valid_ratios.append(r)
                valid_weights.append(w)
        
        if valid_ratios:
            weighted_ratio = sum(r * w for r, w in zip(valid_ratios, valid_weights)) / sum(valid_weights)
        else:
            weighted_ratio = np.nan
        
        # Lookup điểm từ weighted ratio trong năm target
        target_combos = parse_subject_combos(row.get(f'combo_{target_year}', ''))
        if not target_combos:
            target_combos = combos_list[0]  # Fallback to n-1 combos
        
        weighted_ratio_score = lookup_score_from_ratio(
            target_year, target_combos, weighted_ratio, nearby_provinces, summaries
        )
        
        record = {
            'school_code': school_code,
            'major_code': major_code,
            'major_name': major_name,
            'target_year': target_year,
            
            # Score features từ các năm trước
            'score_prev_year': score_prev,
            'score_2year_ago': score_2y,
            'score_3year_ago': score_3y,
            'score_4year_ago': score_4y,
            'score_trend': score_prev - score_2y if not pd.isna(score_2y) else 0,
            'avg_score_3year': np.nanmean([score_prev, score_2y, score_3y]),
            
            # Ratio features từ các năm trước
            'ratio_prev_year': ratio_prev,
            'ratio_2year_ago': ratio_2y,
            'ratio_3year_ago': ratio_3y,
            'ratio_4year_ago': ratio_4y,
            'ratio_trend': ratio_prev - ratio_2y if not pd.isna(ratio_2y) else 0,
            
            # NEW: Weighted ratio lookup score (dùng phổ điểm năm target)
            'weighted_ratio': weighted_ratio,
            'weighted_ratio_score': weighted_ratio_score,
            
            # Target
            'score_target': score_target
        }
        records.append(record)
    
    df = pd.DataFrame(records)
    df = df.dropna(subset=['score_target', 'score_prev_year'])
    df = df.fillna(df.median(numeric_only=True))
    
    return df


# =============================================================================
# 6. MODEL TRAINING & EVALUATION
# =============================================================================

FEATURE_COLS = [
    'score_prev_year', 'score_2year_ago', 'score_3year_ago', 'score_4year_ago',
    'score_trend', 'avg_score_3year',
    'ratio_prev_year', 'ratio_2year_ago', 'ratio_3year_ago', 'ratio_4year_ago', 'ratio_trend',
    'weighted_ratio', 'weighted_ratio_score'  # NEW: Feature từ phổ điểm năm target
]


def train_and_evaluate_models(
    df_train: pd.DataFrame,
    df_valid: pd.DataFrame
) -> Dict:
    """
    Train trên train set, evaluate trên valid set.
    """
    X_train = df_train[FEATURE_COLS].values
    y_train = df_train['score_target'].values
    X_valid = df_valid[FEATURE_COLS].values
    y_valid = df_valid['score_target'].values
    
    # Scale features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)
    
    # Define models
    models = {
        'Linear Regression': LinearRegression(),
        'Ridge Regression': Ridge(alpha=1.0),
        'Lasso Regression': Lasso(alpha=0.1),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
    }
    
    try:
        from xgboost import XGBRegressor
        models['XGBoost'] = XGBRegressor(n_estimators=100, random_state=42, verbosity=0)
    except ImportError:
        pass
    
    results = {}
    best_score = -float('inf')
    best_model = None
    best_model_name = None
    
    print("\n" + "=" * 60)
    print("MODEL EVALUATION ON VALIDATION SET (target=2023)")
    print("=" * 60)
    
    for name, model in models.items():
        if 'Regression' in name:
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_valid_scaled)
        else:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_valid)
        
        mae = mean_absolute_error(y_valid, y_pred)
        rmse = np.sqrt(mean_squared_error(y_valid, y_pred))
        r2 = r2_score(y_valid, y_pred)
        
        results[name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2, 'model': model}
        
        print(f"\n{name}:")
        print(f"  MAE:  {mae:.4f} điểm")
        print(f"  RMSE: {rmse:.4f} điểm")
        print(f"  R²:   {r2:.4f}")
        
        if r2 > best_score:
            best_score = r2
            best_model = model
            best_model_name = name
    
    print("\n" + "=" * 60)
    print(f"BEST MODEL: {best_model_name} (R² = {best_score:.4f})")
    print("=" * 60)
    
    return {
        'results': results,
        'best_model': best_model,
        'best_model_name': best_model_name,
        'scaler': scaler,
        'X_train': X_train,
        'y_train': y_train
    }


def retrain_best_model_on_full_data(model_info: Dict, df_full: pd.DataFrame) -> Dict:
    """Retrain best model trên toàn bộ training data (train + valid)."""
    X_full = df_full[FEATURE_COLS].values
    y_full = df_full['score_target'].values
    
    scaler = StandardScaler()
    X_full_scaled = scaler.fit_transform(X_full)
    
    best_model_name = model_info['best_model_name']
    
    # Recreate model
    if best_model_name == 'Linear Regression':
        model = LinearRegression()
    elif best_model_name == 'Ridge Regression':
        model = Ridge(alpha=1.0)
    elif best_model_name == 'Lasso Regression':
        model = Lasso(alpha=0.1)
    elif best_model_name == 'Random Forest':
        model = RandomForestRegressor(n_estimators=100, random_state=42)
    elif best_model_name == 'Gradient Boosting':
        model = GradientBoostingRegressor(n_estimators=100, random_state=42)
    elif best_model_name == 'XGBoost':
        from xgboost import XGBRegressor
        model = XGBRegressor(n_estimators=100, random_state=42, verbosity=0)
    else:
        model = model_info['best_model']
    
    if 'Regression' in best_model_name:
        model.fit(X_full_scaled, y_full)
    else:
        model.fit(X_full, y_full)
    
    print(f"\nRetrained {best_model_name} on full training data ({len(df_full)} samples)")
    
    return {
        'best_model': model,
        'best_model_name': best_model_name,
        'scaler': scaler
    }


# =============================================================================
# 7. PREDICTION
# =============================================================================

def predict_scores(df_test: pd.DataFrame, model_info: Dict) -> pd.DataFrame:
    """Dự đoán điểm chuẩn."""
    X_test = df_test[FEATURE_COLS].values
    
    model = model_info['best_model']
    model_name = model_info['best_model_name']
    
    if 'Regression' in model_name:
        X_test = model_info['scaler'].transform(X_test)
    
    predictions = model.predict(X_test)
    
    result = df_test[['school_code', 'major_code', 'major_name', 'score_target']].copy()
    result.columns = ['school_code', 'major_code', 'major_name', 'actual']
    result['predicted'] = predictions
    result['error'] = result['predicted'] - result['actual']
    result['abs_error'] = result['error'].abs()
    
    return result


# =============================================================================
# 8. MAIN
# =============================================================================

def main():
    print("=" * 60)
    print("DỰ ĐOÁN ĐIỂM CHUẨN ĐẠI HỌC 2024")
    print("Time-based Split: Train/Valid on 2023, Test on 2024")
    print("=" * 60)
    
    print("\nLoading data...")
    schools, provinces, pretrain, summaries = load_data()
    
    print(f"  Loaded {len(pretrain)} records")
    print(f"  Loaded {len(schools)} schools, {len(provinces)} provinces")
    print(f"  Summaries: {list(summaries.keys())}")
    
    # =========================================================================
    # PHASE 1: Build Training Data (target = 2023)
    # =========================================================================
    print("\n" + "=" * 60)
    print("PHASE 1: TRAINING (target = 2023)")
    print("Features: 2019-2022 → Predict: 2023")
    print("=" * 60)
    
    print("\nBuilding features for target_year=2023...")
    df_2023 = build_training_features(
        pretrain, schools, provinces, summaries,
        target_year=2023, radius_km=500
    )
    print(f"  Built {len(df_2023)} samples")
    
    # Save training features
    df_2023.to_csv(os.path.join(DATA_DIR, 'training_features_2023.csv'), 
                   index=False, encoding='utf-8-sig')
    print(f"  Saved to: training_features_2023.csv")
    
    # Split Train/Valid (80/20)
    df_train, df_valid = train_test_split(df_2023, test_size=0.2, random_state=42)
    
    print(f"\nTrain/Valid Split:")
    print(f"  Train: {len(df_train)} samples (80%)")
    print(f"  Valid: {len(df_valid)} samples (20%)")
    print(f"  Train target mean: {df_train['score_target'].mean():.2f}")
    print(f"  Valid target mean: {df_valid['score_target'].mean():.2f}")
    
    # Train and evaluate
    model_info = train_and_evaluate_models(df_train, df_valid)
    
    # Retrain on full 2023 data
    model_info_full = retrain_best_model_on_full_data(model_info, df_2023)
    
    # =========================================================================
    # PHASE 2: Prediction (target = 2024)
    # =========================================================================
    print("\n" + "=" * 60)
    print("PHASE 2: PREDICTION (target = 2024)")
    print("Features: 2020-2023 → Predict: 2024")
    print("=" * 60)
    
    print("\nBuilding features for target_year=2024...")
    df_2024 = build_training_features(
        pretrain, schools, provinces, summaries,
        target_year=2024, radius_km=500
    )
    print(f"  Built {len(df_2024)} samples")
    
    # Save test features
    df_2024.to_csv(os.path.join(DATA_DIR, 'training_features_2024.csv'), 
                   index=False, encoding='utf-8-sig')
    print(f"  Saved to: training_features_2024.csv")
    
    # Predict
    print("\nPredicting 2024 scores...")
    predictions = predict_scores(df_2024, model_info_full)
    
    # =========================================================================
    # PHASE 3: Evaluation (compare with actual 2024)
    # =========================================================================
    print("\n" + "=" * 60)
    print("PHASE 3: EVALUATION (compare with actual 2024)")
    print("=" * 60)
    
    mae = predictions['abs_error'].mean()
    rmse = np.sqrt((predictions['error'] ** 2).mean())
    
    # Calculate R2
    ss_res = ((predictions['actual'] - predictions['predicted']) ** 2).sum()
    ss_tot = ((predictions['actual'] - predictions['actual'].mean()) ** 2).sum()
    r2 = 1 - (ss_res / ss_tot)
    
    print(f"\nTest Set Metrics (2024):")
    print(f"  MAE:  {mae:.4f} điểm")
    print(f"  RMSE: {rmse:.4f} điểm")
    print(f"  R²:   {r2:.4f}")
    
    print(f"\nError Distribution:")
    print(f"  Errors ≤ 0.5 điểm:  {(predictions['abs_error'] <= 0.5).sum()} ({(predictions['abs_error'] <= 0.5).mean()*100:.1f}%)")
    print(f"  Errors ≤ 1.0 điểm:  {(predictions['abs_error'] <= 1.0).sum()} ({(predictions['abs_error'] <= 1.0).mean()*100:.1f}%)")
    print(f"  Errors ≤ 2.0 điểm:  {(predictions['abs_error'] <= 2.0).sum()} ({(predictions['abs_error'] <= 2.0).mean()*100:.1f}%)")
    print(f"  Errors > 5.0 điểm:  {(predictions['abs_error'] > 5.0).sum()} ({(predictions['abs_error'] > 5.0).mean()*100:.1f}%)")
    
    print("\n--- Top 10 Worst Predictions ---")
    worst = predictions.nlargest(10, 'abs_error')[
        ['school_code', 'major_name', 'actual', 'predicted', 'error']
    ]
    print(worst.to_string())
    
    # Save predictions
    output_path = os.path.join(DATA_DIR, 'predictions_2024.csv')
    predictions.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nPredictions saved to: {output_path}")
    
    # =========================================================================
    # SUMMARY
    # =========================================================================
    print("\n" + "=" * 60)
    print("SUMMARY")
    print("=" * 60)
    print(f"Best Model: {model_info_full['best_model_name']}")
    print(f"Validation R² (2023): {model_info['results'][model_info['best_model_name']]['R2']:.4f}")
    print(f"Test R² (2024): {r2:.4f}")
    
    return predictions, model_info_full


if __name__ == '__main__':
    predictions, model_info = main()
